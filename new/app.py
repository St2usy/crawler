from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import asyncio
import signal
import atexit
from datetime import datetime
from typing import List, Optional
import json
import os
import sys

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from crawler_service import CrawlerService
from models import NoticeResponse, CrawlStatus, CategorySummary

app = FastAPI(
    title="ê³µì§€ì‚¬í•­ í¬ë¡¤ëŸ¬ API",
    description="ì „ë¶ëŒ€í•™êµ ì»´í“¨í„°ê³µí•™ë¶€ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§ API",
    version="1.0.0"
)

# CORS ì„¤ì • (React ì—°ë™ì„ ìœ„í•´)
# 
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],  # React ê°œë°œ ì„œë²„ ì£¼ì†Œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# í¬ë¡¤ëŸ¬ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
crawler_service = CrawlerService()

def cleanup_resources():
    """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ í•¨ìˆ˜"""
    try:
        print("\nğŸ”„ ì„œë²„ ì¢…ë£Œ ì¤‘... ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.")
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€
        if hasattr(crawler_service, 'scheduler_service'):
            crawler_service.scheduler_service.stop_scheduler()
            print("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€ ì™„ë£Œ")
        
        # Firebase ì—°ê²° ì •ë¦¬
        if hasattr(crawler_service, 'firebase_service'):
            crawler_service.firebase_service.cleanup()
            print("âœ… Firebase ì—°ê²° ì •ë¦¬ ì™„ë£Œ")
        
        print("âœ… ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# ì¢…ë£Œ ì‹œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ë“±ë¡
atexit.register(cleanup_resources)

# ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡ (Ctrl+C, ì¢…ë£Œ ì‹ í˜¸)
def signal_handler(signum, frame):
    print(f"\nğŸ›‘ ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹  ({signum})")
    cleanup_resources()
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)   # Ctrl+C
signal.signal(signal.SIGTERM, signal_handler)  # ì¢…ë£Œ ì‹ í˜¸

@app.get("/", response_model=dict)
async def root():
    """API ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "ê³µì§€ì‚¬í•­ í¬ë¡¤ëŸ¬ API",
        "version": "1.0.0",
        "status": "running"
    }

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.get("/notices", response_model=List[NoticeResponse])
async def get_notices(
    category: Optional[str] = None,
    limit: Optional[int] = None,
    offset: Optional[int] = 0
):
    """ê³µì§€ì‚¬í•­ ëª©ë¡ ì¡°íšŒ"""
    try:
        notices = await crawler_service.get_notices(category, limit, offset)
        return notices
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/notices/{notice_id}", response_model=NoticeResponse)
async def get_notice(notice_id: str):
    """íŠ¹ì • ê³µì§€ì‚¬í•­ ìƒì„¸ ì¡°íšŒ"""
    try:
        notice = await crawler_service.get_notice_by_id(notice_id)
        if not notice:
            raise HTTPException(status_code=404, detail="ê³µì§€ì‚¬í•­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return notice
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/categories", response_model=List[str])
async def get_categories():
    """ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¡°íšŒ"""
    try:
        categories = await crawler_service.get_categories()
        return categories
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/summary", response_model=List[CategorySummary])
async def get_summary():
    """ì¹´í…Œê³ ë¦¬ë³„ ìš”ì•½ ì •ë³´ ì¡°íšŒ"""
    try:
        summary = await crawler_service.get_summary()
        return summary
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/crawl", response_model=CrawlStatus)
async def start_crawl(background_tasks: BackgroundTasks):
    """í¬ë¡¤ë§ ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)"""
    try:
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ í¬ë¡¤ë§ ì‹¤í–‰
        background_tasks.add_task(crawler_service.crawl_new_posts)
        
        return CrawlStatus(
            status="started",
            message="í¬ë¡¤ë§ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤",
            timestamp=datetime.now().isoformat()
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/crawl/full", response_model=CrawlStatus)
async def start_full_crawl(background_tasks: BackgroundTasks):
    """ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)"""
    try:
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰
        background_tasks.add_task(crawler_service.crawl_all_posts)
        
        return CrawlStatus(
            status="started",
            message="ì „ì²´ í¬ë¡¤ë§ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤",
            timestamp=datetime.now().isoformat()
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/crawl/status", response_model=CrawlStatus)
async def get_crawl_status():
    """í¬ë¡¤ë§ ìƒíƒœ ì¡°íšŒ"""
    try:
        status = await crawler_service.get_crawl_status()
        return status
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/search")
async def search_notices(
    query: str,
    category: Optional[str] = None,
    limit: Optional[int] = 20
):
    """ê³µì§€ì‚¬í•­ ê²€ìƒ‰"""
    try:
        results = await crawler_service.search_notices(query, category, limit)
        return {
            "query": query,
            "results": results,
            "total": len(results)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/latest")
async def get_latest_notices(limit: int = 10):
    """ìµœì‹  ê³µì§€ì‚¬í•­ ì¡°íšŒ"""
    try:
        notices = await crawler_service.get_latest_notices(limit)
        return notices
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/scheduler/start")
async def start_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
    try:
        crawler_service.start_scheduler()
        return {"message": "ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤", "timestamp": datetime.now().isoformat()}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/scheduler/stop")
async def stop_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
    try:
        crawler_service.stop_scheduler()
        return {"message": "ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤", "timestamp": datetime.now().isoformat()}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/scheduler/status")
async def get_scheduler_status():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ì¡°íšŒ"""
    try:
        status = crawler_service.get_scheduler_status()
        return status
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.put("/scheduler/interval")
async def update_crawl_interval(minutes: int):
    """í¬ë¡¤ë§ ê°„ê²© ì—…ë°ì´íŠ¸"""
    try:
        if minutes < 1:
            raise HTTPException(status_code=400, detail="í¬ë¡¤ë§ ê°„ê²©ì€ ìµœì†Œ 1ë¶„ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤")
        
        success = crawler_service.update_crawl_interval(minutes)
        if success:
            return {"message": f"í¬ë¡¤ë§ ê°„ê²©ì´ {minutes}ë¶„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤", "interval": minutes}
        else:
            raise HTTPException(status_code=400, detail="í¬ë¡¤ë§ ê°„ê²© ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/crawl/now")
async def run_crawl_now():
    """ì¦‰ì‹œ í¬ë¡¤ë§ ì‹¤í–‰"""
    try:
        success = crawler_service.run_crawl_now()
        if success:
            return {"message": "í¬ë¡¤ë§ì´ ì¦‰ì‹œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤", "timestamp": datetime.now().isoformat()}
        else:
            raise HTTPException(status_code=500, detail="í¬ë¡¤ë§ ì‹¤í–‰ ì‹¤íŒ¨")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/firebase/stats")
async def get_firebase_stats():
    """Firebase í†µê³„ ì •ë³´ ì¡°íšŒ"""
    try:
        stats = await crawler_service.get_firebase_stats()
        return stats
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/firebase/sync")
async def sync_to_firebase():
    """ë¡œì»¬ ë°ì´í„°ë¥¼ Firebaseì— ë™ê¸°í™”"""
    try:
        result = await crawler_service.sync_to_firebase()
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/firebase/test")
async def test_firebase_connection():
    """Firebase ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        result = await crawler_service.test_firebase_connection()
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
